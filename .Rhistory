print(i)
start <- start + 1
for (j in (start:length(x))){
print(j)
}
}
start <- 1
for (i in (2:length(x)-1)){
print(i)
start <- start + 1
for (j in (start:length(x))){
print(j)
}
}
for (i in (2:length(x)-1)) {
start <- start + 1
for (j in (start:length(x))) {
print(x[i])
print(x[j])
if (x[i] == x[j]) {
return(TRUE)
}
}
}
start <- 1
for (i in (2:length(x)-1)) {
start <- start + 1
for (j in (start:length(x))) {
print(x[i])
print(x[j])
if (x[i] == x[j]) {
return(TRUE)
}
}
}
# 1. Naive Linear Search
duplicate1 <- function(x) {
start <- 1
for (i in (2:length(x)-1)) {
start <- start + 1
for (j in (start:length(x))) {
if (x[i] == x[j]) {
return(TRUE)
}
}
}
return(FALSE)
}
duplicate1(x)
x <- c(1, 2, 3, 4, 5, 6)
duplicate1(x)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:length(x))) {
if (x[i] == num[i+1])
return(TRUE)
}
return(FALSE)
}
duplicate2(x)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:length(x))) {
if (x[i] == x[i+1])
return(TRUE)
}
return(FALSE)
}
duplicate2(x)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:length(x))) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(x)
i <- 1
rm(x, j)
rm(i, j)
rm(i, j, start)
x <- c(1, 2, 3, 4, 5, 6)
y <- c(2, 4, 6, 8, 6, 10)
print(i)
for (i in (1:length(x))) {
print(i)
}
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:length(x)-1)) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(x)
rm(i)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:length(x)-1)) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(x)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:(length(x)-1))) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(x)
duplicate2(y)
duplicate1(y)
for (k in (1:(length(x)-1))) {
print(i)
print(i+1)
}
for (k in (1:(length(x)-1))) {
print(k)
print(k+1)
}
sort(x)
sort(y)
# 2. Sorting
duplicate2 <- function(x) {
sort(x)
for (i in (1:(length(x)-1))) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(y)
for (k in (1:(length(y)-1))) {
print(k)
print(k+1)
}
for (k in (1:(length(y)-1))) {
print(y[k])
print(y[k+1])
}
# 2. Sorting
duplicate2 <- function(x) {
x <- sort(x)
for (i in (1:(length(x)-1))) {
if (x[i] == x[i+1]) {
return(TRUE)
}
}
return(FALSE)
}
duplicate2(y)
duplicate2(x)
# 3. Hash Table
duplicate3 <- function(x) {
hash <- c()
j <- 1
for (i in x) {
if (is.element(i, hash[j]) == TRUE){
return(TRUE)
}
else {
hash[j] <- i
j <- j + 1
}
}
return(FALSE)
}
duplicate3(x)
duplicate3(y)
is.element(y[1], y)
for (i in x) {
print(i)
print(h[k])
if (is.element(i, hash[k]) == TRUE){
return(TRUE)
}
else {
k <- k+1
}
}
h <- c()
k <- 1
for (i in x) {
print(i)
print(h[k])
if (is.element(i, hash[k]) == TRUE){
return(TRUE)
}
else {
k <- k+1
}
}
if (is.element(i, h[k]) == TRUE){
return(TRUE)
}
for (i in x) {
print(i)
print(h[k])
if (is.element(i, h[k]) == TRUE){
return(TRUE)
}
else {
k <- k+1
}
}
h <- c()
k <- 1
for (i in y) {
print(i)
print(h[k])
if (is.element(i, h[k]) == TRUE){
return(TRUE)
}
else {
h[k] <- i
k <- k+1
}
}
for (i in y) {
print(i)
print(h[k])
if (is.element(i, h) == TRUE){
return(TRUE)
}
else {
h[k] <- i
k <- k+1
}
}
h <- c()
k <- 1
for (i in y) {
print(i)
print(h[k])
if (is.element(i, h) == TRUE){
return(TRUE)
}
else {
h[k] <- i
k <- k+1
}
}
h <- c()
k <- 1
for (i in y) {
print(i)
print(h)
if (is.element(i, h) == TRUE){
return(TRUE)
}
else {
h[k] <- i
k <- k+1
}
}
h <- c()
k <- 1
for (i in y) {
print(i)
print(h)
if (is.element(i, h) == TRUE){
print(TRUE)
}
else {
h[k] <- i
k <- k+1
}
}
# 3. Hash Table
duplicate3 <- function(x) {
hash <- c()
j <- 1
for (i in x) {
if (is.element(i, hash) == TRUE){
return(TRUE)
}
else {
hash[j] <- i
j <- j + 1
}
}
return(FALSE)
}
duplicate3(y)
duplicate3(x)
# In this section, we are going to use the tree-based methods for regresssion and classification.
# We first need to install the 'randomForest' and 'ISLR' packages
install.packages("randomForest")
install.packages("ISLR")
install.packages("tree")
# Import the libraries for analysis
library(randomForest)
library(ISLR)
library(tree)
library(MASS)
# Splitting data into training and testing sets (50/50)
set.seed(1)
NumberofObservations = dim(Boston)[1]
SplitofTrainTest = 0.5 #let's split the data 50/50
train = sample(1:NumberofObservations,NumberofObservations*SplitofTrainTest)
test = -train
trainingData = Boston[train,]
testingData  = Boston[test,]
Testing_outcome = Boston$medv[test]
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv~., data=trainingData, mtry=13, importance=TRUE)
# mtry is the number of variables randomly sampled as candidates at each slpit.
# The default is sqrt(p) in classification and p/3 in regression
# The default number of trees is 500
bag.boston
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv-., data=trainingData, mtry=13, importance=TRUE)
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv -., data=trainingData, mtry=13, importance=TRUE)
View(testingData)
# Bagging is simply a special case of random forest with m = p (All predictors are used to grow trees)
bag.boston = randomForest(medv - ., data=trainingData, mtry=13, importance=TRUE)
?Salary
?Hitters
dim(Hitters)
install.packages("sna")
install.packages("igraph")
setwd("C:/Users/lokma/Desktop/Social_Network_Analysis_with_R")
getwd()
g1 <- read.table('data/undirected.txt')
head(g1)
graph1 <- graph_from_data_frame(g1)
library(sna)
library(igraph)
install.packages("sna")
install.packages("igraph")
library(sna)
library(igraph)
graph1 <- graph_from_data_frame(g1, directed = False, vertices = NULL)
graph1 <- graph_from_data_frame(g1, directed = FALSE, vertices = NULL)
plot(graph1)
# Create Sample Graph
g_full <- make_full_graph(8, directed = FALSE)
plot(g_full)
g_ring <- make_ring(12, directed = FALSE, mutual = FALSE, circular = TRUE)
plot(g_ring)
# Star graph with a central vertex and 10 nodes,
g_star <- make_star(10, center = 1)
plot(g_star)
plot(g_gnp)
# GNP graph
g_gnp <- sample_gnp(20, 0.3, directed = FALSE, loops = FALSE)
plot(g_gnp)
plot(gnm)
# GNM graph
g_gnm <- sample_gnm(20, 50, directed = FALSE, loops = FALSE)
plot(gnm)
# GNM graph
g_gnm <- sample_gnm(20, 50, directed = FALSE, loops = FALSE)
plot(g_gnm)
# Other models, such as preferential attachment
# Create a network starts with two linked nodes, then use a weighted probabiity distribution
# to determine which node to attach the next node to.
# Preferential Attachement (PA) model with 20 vertices, power=1
# power parameter, weight to give to each of the connections, equal one means equal weight to each connection
g_gpa <- sample_pa(20, power = 1)
plot(g_gpa)
# Practice with the preferential attachemnet model
g2 <- sample_pa(12, power = 1, directed = FALSE)
plot(g2)
# Check the degrees for each of the node means the number of links that it has
degree(g2)
# Practice with the preferential attachement model
g3 <- sample_pa(20, power = 1, directed = FALSE)
plot(g3)
# Check the betweenness of the network
betweenness(g3)
# Practice with preferential attachment model
g4 <- sample_pa(12, power = 1, directed = FALSE)
plot(g4)
# Check the edge density
ed <- edge_density(g4, loops = FALSE)
ed
# Practice with preferential attachment model (20 nodes)
g5 <- sample_pa(20, power = 1, directed = FALSE)
plot(g5)
# Check the edge density
ed <- edge_density(g5, loops = FALSE)
ed
# Practice with preferential attachment model (40 nodes)
g6 <- sample_pa(40, power = 1, directed = FALSE)
plot(g6)
# Check the edge density
ed <- edge_density(g6, loops = FALSE)
ed # 2 / 20 = 0.1
# Practice with GMP model (20 nodes)
g7 <- sample_gmp(20, 0.3, directed = FALSE)
# Practice with GNP model (20 nodes)
g7 <- sample_gnp(20, 0.3, directed = FALSE)
plot(g7)
# Check the edge density
ed <- edge_density(g7, loops = FALSE)
ed # 2 / 40 = 0.05
# Practice with GNP model (20 nodes)
g8 <- sample_gnp(20, 0.3, directed = FALSE, loops = FALSE)
plot(g8)
# Analyze the Clique
# 1. Calculate the size of the largest clique (largest fully-connected subgroup within the network)
clique_num(g8)
# Display the number of cliques that are of a particular size
# Let says size 4
cliques(gnp, min = 4)
# Display the number of cliques that are of a particular size
# Let says size 4
cliques(g8, min = 4)
# Find min equals 3 and max equals 4
cliques(g8, min = 3, max = 4)
# Practice with GNP model (20 nodes and probability = 0.6)
g9 <- sample_gnp(20, 0.6, directed = FALSE, loops = FALSE)
plot(g9)
# The network becomes very highly interconnected
# Check the largest clique number again,
clique_num(g9)
# Practice with GNP model (20 nodes and probability = 0.8)
# Only 8% probability of any individual link being available
g10 <- sample_gnp(20, 0.8, directed = FALSE, loops = FALSE)
plot(g9)
# Practice with GNP model (30 nodes and probability = 0.8)
# Only 8% probability of any individual link being available
g10 <- sample_gnp(30, 0.8, directed = FALSE, loops = FALSE)
plot(g9)
# Practice with GNP model (30 nodes and probability = 0.08)
# Only 8% probability of any individual link being available
g10 <- sample_gnp(30, 0.08, directed = FALSE, loops = FALSE)
plot(g9)
plot(g10)
# Number of components in the graph and get information about them
components(g10)
# Practice with GNP model (30 nodes and probability = 0.08)
# Only 8% probability of any individual link being available
g11 <- sample_gnp(30, 0.08, directed = FALSE, loops = FALSE)
plot(g11)
# Create a random walk started with node #21, number of steps = 8, stuck = "return"
random_walk(g11, 21, 8, stuck = "return")
# If the random walk starts at the node with no connection, it couldn't go further in the path
random_walk(g11, 5, 8, stuck = "return")
# Practice with GNP model (20 nodes and probability = 0.1)
g <- sample_gnp(20, 0.1, directed = FALSE, loops = FALSE)
plot(g)
# Change edge and vertex colors
g <- sample_gnp(20, 0.1) %>%
set_vertex_attr("color", value = "blue") %>%
set_edge_attr("color", value = "green")
plot(g)
getwd()
write.graph(g, file = "data/gnp_graph.txt", format = "edgelist")
# Write the graph to the local drive
pdf("images/gnp_graph.pdf")
div.off()
plot(g)
div.off()
dev.off()
# Write out the data and graph
g <- sample_gnp(20, 0.1)
plot(g)
# Write the graph to the local drive
pdf("images/gnp_graph.pdf")
plot(g)
dev.off()
# Write the graph to local drive in png format
png("images/gnp_graph.png", width = 350, height = "350")
# Write the graph to local drive in png format
png("images/gnp_graph.png", width = 350, height = 350)
plot(g)
dev.off()
# Write the graph to local drive in png format
png("images/gnp_graph.png", width = 500, height = 500)
plot(g)
dev.off()
# Create a graph from the undirected data set
graph1 <- graph_from_data_frame(g1, directed = TRUE, vertices = NULL)
plot(graph1)
# Loading the undirected data set
g1 <- read.table('data/directed.txt')
head(g1)
# Create a graph from the undirected data set
graph1 <- graph_from_data_frame(g1, directed = FALSE, vertices = NULL)
plot(graph1)
# Loading the undirected data set
g1 <- read.table('data/undirected.txt')
head(g1)
# Create a graph from the undirected data set
graph1 <- graph_from_data_frame(g1, directed = FALSE, vertices = NULL)
plot(graph1)
# Loading the directed data set
g1 <- read.table('data/directed.txt')
head(g1)
# Create a graph from the undirected data set
graph1 <- graph_from_data_frame(g1, directed = TRUE)
plot(graph1)
